{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain import HuggingFaceHub, LLMChain,PromptTemplate\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_code = \"codellama/CodeLlama-34b-Instruct-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_code = HuggingFaceHub(huggingfacehub_api_token = hf_key, repo_id= model_type_code, model_kwargs={\"temperature\":0.1, \"max_new_tokens\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(llm_code, df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should look at the data to figure out what the types should be.\n",
      "Action: python_repl_ast\n",
      "Action Input: print(df.head())\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m                 date                            title  \\\n",
      "0 2023-11-01 16:12:19                   Google Takeout   \n",
      "1 2023-11-01 16:12:17                   Google Takeout   \n",
      "2 2023-11-01 16:11:49             CSC 2516 | Piazza QA   \n",
      "3 2023-11-01 16:11:07             CSC 2516 | Piazza QA   \n",
      "4 2023-11-01 16:11:03  CSC 2516 (1 unread) | Piazza QA   \n",
      "\n",
      "                                               url  \n",
      "0                      https://takeout.google.com/  \n",
      "1                      https://takeout.google.com/  \n",
      "2  https://piazza.com/class/lmhqcchw29mpw/post/172  \n",
      "3  https://piazza.com/class/lmhqcchw29mpw/post/173  \n",
      "4  https://piazza.com/class/lmhqcchw29mpw/post/174  \n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should convert the date column to datetime.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['date'] = pd.to_datetime(df['date'])\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should convert the title column to string.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['title'] = df['title'].astype(str)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should convert the url column to string.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['url'] = df['url'].astype(str)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should now know the final answer.\n",
      "Final Answer: df['date'] = pd.to_datetime(df['date'])\n",
      "df['title'] = df['title'].astype(str)\n",
      "df['url'] = df['url'].astype(str)\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(\"Figure out what should be the type of each column of the dataframe, and answer with a Python script to convert the columns to the correct type. To separate each line of code, use '\\n'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Pix2StructProcessor.from_pretrained('google/deplot')\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "df = pd.read_csv('data/physionet_cleaned/sleep.csv')\n",
    "fig=px.line(df,x=\"date\",y=\"avgdurationasleep\", color_discrete_sequence=px.colors.qualitative.G10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bytes = fig.to_image(format=\"png\")\n",
    "img = Image.open(io.BytesIO(img_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE |  <0x0A> date | avgdurationasleep <0x0A> Apr 15<0x0A>2018 | 45 <0x0A> Apr 29 | 38 <0x0A> May 13 | 46 <0x0A> May 27 | 43 <0x0A> Jun 10 | 91 <0x0A> Jun 24 | 119\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(images=img, text=\"Generate information from the figure below:\", return_tensors=\"pt\")\n",
    "predictions = model.generate(**inputs, max_new_tokens=512)\n",
    "answer = processor.decode(predictions[0], skip_special_tokens=True)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"HuggingFaceH4/zephyr-7b-beta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_to_ask = \"Given the following description of a figure, generate a few sentences about it:\"\n",
    "question_to_ask += \"\\n\\n\" + answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnouvina/Desktop/UofT/UbiComp/csc2524/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning:\n",
      "\n",
      "'__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(huggingfacehub_api_token = hf_key, repo_id= model_type, model_kwargs={\"temperature\":0.1, \"max_new_tokens\":500})\n",
    "llm_prompt = PromptTemplate.from_template(question_to_ask)\n",
    "llm_chain = LLMChain(llm=llm,prompt=llm_prompt)\n",
    "llm_response = llm_chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <0x0A> Jul 08 | 114 <0x0A> Jul 22 | 112 <0x0A> Aug 05 | 111 <0x0A> Aug 19 | 111 <0x0A> Sep 02 | 112 <0x0A> Sep 16 | 112 <0x0A> Sep 30 | 111 <0x0A> Oct 14 | 111 <0x0A> Oct 28 | 111 <0x0A> Nov 11 | 111 <0x0A> Nov 25 | 111 <0x0A> Dec 09 | 111 <0x0A> Dec 23 | 111 <0x0A>\n",
      "\n",
      "The provided data shows a consistent pattern of sleep duration for an individual, with an average of approximately 111 minutes per night from April to December 2018. The longest period of sleep recorded was 91 minutes on June 10, while the shortest was 38 minutes on April 29. The majority of sleep durations fell within the range of 110-114 minutes, with only a few instances of shorter or longer sleep periods. Overall, the data suggests a relatively stable sleep pattern for this individual during the given timeframe.\n"
     ]
    }
   ],
   "source": [
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
